{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "import io\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import ipympl\n",
    "\n",
    "\n",
    "#import the ipywidgets module and the IPython display function\n",
    "from ipywidgets import interactive, HBox, Layout, Button, GridspecLayout\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
    "\n",
    "import os\n",
    "#print(os.listdir(\"./input\"))\n",
    "\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!jupyter nbextension enable --py widgetsnbextension --sys-prefix\n",
    "#!jupyter serverextension enable voila --sys-prefix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67e8f079390f47dabcc57fd77cbe5be2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HTML(value='<h1>Analysis of Poetry using Random Forest Classifier</h1>')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "headline = widgets.HTML(value=\"<h1>Analysis of Poetry using Random Forest Classifier</h1>\")\n",
    "headline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "584c60c1ab9f4156b867190867376577",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(VBox(children=(HTML(value='<h4>Upload data file in .csv format</h4>'), FileUpload(value={}, accâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e33c7da80f84e36a165568f194426b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Analyze', style=ButtonStyle(button_color='lime'), tooltip='success')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "text_1 = widgets.HTML(value=\"<h4>Upload data file in .csv format</h4>\")\n",
    "\n",
    "\n",
    "button_execute = widgets.Button(\n",
    "                description='Analyze',\n",
    "                tooltip='success',\n",
    "                style={'description_width': 'initial'}\n",
    "            )\n",
    "\n",
    "#upload btn\n",
    "uploader = widgets.FileUpload(\n",
    "    accept='*.csv',  # Accepted file extension e.g. '.txt', '.pdf', 'image/*', 'image/*,.pdf'\n",
    "    multiple=False  # True to accept multiple files upload else False\n",
    ")\n",
    "\n",
    "#styles\n",
    "button_execute.style.button_color = 'lime'\n",
    "uploader.style.button_color = 'yellow'\n",
    "\n",
    "#hbox and vbox\n",
    "liner = widgets.VBox([text_1, uploader])\n",
    "page = widgets.HBox([ liner])\n",
    "display(page)\n",
    "#df = pd.read_csv(\"./input/all.csv\")\n",
    "content = '';\n",
    "def on_button_clicked(event):\n",
    "        input_file = list(uploader.value.values())[0]\n",
    "        content = input_file['content']\n",
    "        content = io.StringIO(content.decode('utf-8'))\n",
    "        df = pd.read_csv(content) \n",
    "        print(\"Analyzed csv file!\")\n",
    "    \n",
    "button_execute.on_click(on_button_clicked)\n",
    "button_execute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from spacy.lang.en.stop_words import STOP_WORDS\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import spacy\n",
    "from spacy.lang.en import English\n",
    "from spacy import displacy\n",
    "import en_core_web_sm\n",
    "nlp = en_core_web_sm.load()\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_kg_hide-output": true,
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./input/all.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_uuid": "a2144f4809e2d15506549c259af9a58d6336fc9f",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [9]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m author_list \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mauthor\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mtolist()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "author_list = df['author'].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "author_list[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "25dd99c58f5dbbeb07d4859efde525f99cd5f65c",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sentences1 = df['content'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#df['content']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sentences2 = list()\n",
    "for element in sentences1:\n",
    "    element = element.replace(\"\\n\",\" \")\n",
    "    element = element.replace(\"\\r\",\"\")\n",
    "    element = element.replace(\",\",\"\")\n",
    "    element = element.replace(\".\",\"\")\n",
    "    element = element.replace(\";\",\"\")\n",
    "    element = element.replace(\":\",\"\")\n",
    "    element = element.replace(\"?\",\"\")\n",
    "    element = element.replace(\"!\",\"\")\n",
    "    sentences2.append(element)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sent_list = []\n",
    "for i in range (len(sentences2)):\n",
    "    str1 = sentences2[i].split(\" \")\n",
    "    sent_list.append(str1)\n",
    "#print(sent_list[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#print(len(sent_list))\n",
    "#print(len(author_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Removing the blank spaces\n",
    "b = list()\n",
    "for mylist in sent_list:\n",
    "    temp = list()\n",
    "    for word in mylist:\n",
    "        if word is not \"\":\n",
    "            temp.append(word)\n",
    "    b.append(temp)\n",
    "sent_list = b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Nouns = 0\n",
    "Verbs = 0\n",
    "Adjectives = 0\n",
    "noun_count = []\n",
    "verb_count = []\n",
    "adjective_count = []\n",
    "\n",
    "for i in range(len(sent_list)):\n",
    "    for j in range(len(sent_list[i])):\n",
    "        #print(sent_list[i][j])\n",
    "        word = nlp(sent_list[i][j])\n",
    "        for token in word:\n",
    "            if token.pos_ == 'VERB':\n",
    "                Verbs= Verbs + 1\n",
    "            elif token.pos_ == 'NOUN':\n",
    "                Nouns= Nouns + 1\n",
    "            elif token.pos_ == 'ADJ':\n",
    "                Adjectives= Adjectives + 1\n",
    "    noun_count.append(Nouns)\n",
    "    verb_count.append(Verbs)\n",
    "    adjective_count.append(Adjectives)\n",
    "Nouns = 0\n",
    "Verbs = 0\n",
    "Adjective = 0\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#print(len(noun_count), len(verb_count), len(adjective_count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.loc[:, \"noun_count\"] = noun_count\n",
    "df.loc[:, \"verb_count\"] = verb_count\n",
    "df.loc[:, \"adjective_count\"] = adjective_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#splitting the text in to words for analysis purpose\n",
    "parsed = list()\n",
    "for i in range(len(sent_list)):\n",
    "    for j in range(len(sent_list[i])):\n",
    "        if sent_list[i][j] not in parsed:\n",
    "            p1 = sent_list[i][j].split(' ')\n",
    "            parsed.append(p1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#print(\"Total Nouns in the data set\",df['noun_count'].sum())\n",
    "#print(\"Total Verbs in the data set\",df['verb_count'].sum())\n",
    "#print(\"Total Adjectives in the data set\", df['adjective_count'].sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    Number Remover\n",
    "\"\"\"\n",
    "number_remove = []\n",
    "for sublist in sent_list:\n",
    "    mysublist = []\n",
    "    for word in sublist:\n",
    "        myword = \"\"\n",
    "        for alphaneumeric in list(word):\n",
    "            if re.search(\"[0-9]\", alphaneumeric):\n",
    "                pass\n",
    "            else:\n",
    "                myword+=alphaneumeric\n",
    "        mysublist.append(myword)\n",
    "    number_remove.append(mysublist)\n",
    "#number_remove[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#len(parsed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "stopwords = STOP_WORDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "s = []\n",
    "\n",
    "for i in range(len(sent_list)):\n",
    "    for str in sent_list[i]:\n",
    "        s_list = [word for word in str.split(\" \") if word not in stopwords]\n",
    "        #print(s_list)\n",
    "        str_ = ' '.join(s_list)   \n",
    "    s.append(str_) \n",
    "        #print(s)\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#creating a list of unique words\n",
    "parsed_stop = []\n",
    "for i in range(len(s)):\n",
    "    for word in s[i].split(' '):\n",
    "        if word not in parsed_stop:\n",
    "            parsed_stop.append(word)\n",
    "#print(parsed_stop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import itertools\n",
    "import collections\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "sns.set(font_scale=1.5)\n",
    "sns.set_style(\"whitegrid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "filtered_sentence =[] \n",
    "for i in range(len(sent_list)):\n",
    "    for j in range(len(sent_list[i])):\n",
    "        #print(sent_list[i][j])\n",
    "        word = nlp(sent_list[i][j])\n",
    "        for token in word:\n",
    "            token_list = []\n",
    "            #toke.lower\n",
    "            token_list.append(token.lower_)\n",
    "            for word in token_list:\n",
    "                lexeme = nlp.vocab[word]\n",
    "                if (lexeme.is_stop == False) and (lexeme.is_punct == False) and (lexeme.is_oov == True):\n",
    "                     filtered_sentence.append(word)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Create counter\n",
    "counts_no_stopwords = collections.Counter(filtered_sentence)\n",
    "\n",
    "#counts_no_stopwords.most_common(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib widget\n",
    "\n",
    "clean_sentences = pd.DataFrame(counts_no_stopwords.most_common(50),\n",
    "                             columns=['words', 'count'])\n",
    "\n",
    "#original1 gayab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "comment_words = ' '\n",
    "for i in range(len(sent_list)):\n",
    "    for j in range(len(sent_list[i])):\n",
    "        comment_words = comment_words + sent_list[i][j] + ' '         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "wordcloud = WordCloud(width = 800, height = 800, \n",
    "background_color ='white', \n",
    "stopwords = stopwords, \n",
    "min_font_size = 10).generate(comment_words) \n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12,8))\n",
    "\n",
    "\n",
    "\n",
    "text_3= widgets.HTML(value=\"<h1>Common Words Found in the Poems without stopwords</h1>\");\n",
    "\n",
    "vbox_text3= widgets.VBox([text_3])\n",
    "\n",
    "page = widgets.HBox([vbox_text3])\n",
    "display(page)\n",
    "\n",
    "\n",
    "# Plot horizontal bar graph\n",
    "clean_sentences.sort_values(by='count').plot.barh(fontsize=10,x='words',\n",
    "                      y='count',\n",
    "                      ax=ax,\n",
    "                      color=\"purple\")\n",
    "\n",
    "\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#original2 gayab\n",
    "# plot the WordCloud image\n",
    "#lt.figure(figsize = (5, 5), facecolor = None) \n",
    "#lt.imshow(wordcloud) \n",
    "#lt.axis(\"off\") \n",
    "#lt.tight_layout(pad = 0) \n",
    "\n",
    "#lt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "bde1261ebb168cb68356f3ddd0ed79b7fb924f52",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cnt_vectorizer = CountVectorizer()\n",
    "features = cnt_vectorizer.fit_transform(s)\n",
    "features_nd = features.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_subset = pd.DataFrame({\"age\": df['age'], \"type\": df['type'], \"Noun_count\":df['noun_count'], \n",
    "                                  \"Verb_count\":df['verb_count'], \"Adjective_count\":df['adjective_count']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_subset = pd.get_dummies(df_subset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Final = np.column_stack((features_nd,df_subset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test  = train_test_split(Final, author_list, train_size=0.75,random_state=1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "clf1 = MultinomialNB()\n",
    "clf1.fit(X_train, y_train)\n",
    "y_pred = clf1.predict(X_test)\n",
    "#accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "clf2 =SVC()\n",
    "clf2.fit(X_train, y_train)\n",
    "y_pred = clf2.predict(X_test)\n",
    "#accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf = RandomForestClassifier(n_estimators=100, oob_score=True, random_state=123456)\n",
    "rf.fit(X_train, y_train)\n",
    "y_pred = rf.predict(X_test)\n",
    "#accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "dda97128eb43bee4883666e7b1f88bf87996b7c6",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#df['type'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "a975a6301f3c9f7ca5c140ddc10c6bf9b163b406",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#df['author'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "4081f317981ec22a0cb28af570290a3d1696b95a",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#df['age'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "f1d1fcea21ff78912db0dc786662b8eef6c759d9",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_modern = df[df['age'] == 'Modern']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "74594317c3a44c4bb063ffed21bb32bf69ebd77b",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#df_modern.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "a3a62822869011b5aae12bf8e50ed297a87f17c3",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#df_modern['author'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "458b0de6c9d231cf9fd42bc9a13688ba83f9e005",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "modern_poetry = df_modern[['author', 'poem name']].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "ade1477c84ea6e3515385a1659e0e7a83677ad89",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#modern_poetry.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "fc19391d4fd70e6b18da793af34cf532e4039bcb",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "authors = df['author'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "b331c50158a48b5609c8609a46fad74aaa4006b1",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#authors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "86016dcb707ce97501247745cfc03a8844e84948",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "e354cab773ac2a2b07108c4d2ceb32f94d68d346",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "age = df['age'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "8b19c98cb2f54288b08d22d5216cfe6b48260a95",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "genre = df['type'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "aaa4e1fd66fb72c9c262177847155dbe9c1c67b6",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#df['age'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "cab927b073b61a9860e7b08165f5be3851d77f92",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#df['type'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "499522d684c3b99e60211c25a96e7661609edbcb",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "G =nx.Graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "799abdfdeb64ebffdce294db24a72ae2c9989551",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "G.add_nodes_from(age)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "53b1539560337df60530d1a5422e0859f60df2c6",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "G.add_nodes_from(genre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "b8f4659436e0dbf774185ce5da443bd226254ff7",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "G.add_nodes_from(authors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "10a6ad0c36073584b63f663e55a2350a2a3e84f9",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#G.nodes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "88633081ab668075015f7404082c59019fe9ebd5",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "myEdges = [tuple(element) for element in df[['author','type']].values]\n",
    "myEdges2 = [tuple(element) for element in df[['author', 'age']].values]\n",
    "myEdges3 = [tuple(element) for element in df[['age', 'type']].values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "625c4dd74338c10200d00849676d38c1fb40e56e",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "G.add_edges_from(myEdges)\n",
    "G.add_edges_from(myEdges2)\n",
    "G.add_edges_from(myEdges3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "7950f519167ebdaf83e03768ee1b18309bb5af41",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#myEdges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "05a28b8c66440b724df0a298ea9d2f6fceb025d3",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "text_2 = widgets.HTML(value=\"<h1>Network Graph</h1>\")\n",
    "\n",
    "vbox_text2 = widgets.VBox([text_2])\n",
    "\n",
    "page = widgets.HBox([vbox_text2])\n",
    "display(page)\n",
    "\n",
    "#%matplotlib inline\n",
    "#fig = plt.figure(3, figsize=(20, 10))\n",
    "fig = plt.figure(3, figsize=(12, 8))\n",
    "nx.draw_spring(G, with_labels=True, font_weight='normal',font_size=12,node_size=100)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "f6382c165d4839070f325448519ae1abebe4bd5f",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#nx.density(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "9d090fad3171621a38a0e91062239daec8663417",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#nx.number_of_nodes(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "e99a10bc39b6d9de43fa7b2b2eeaba0f300e57ce",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#nx.number_of_edges(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "d93265e20c3de88fb1883c7a863538eea922afef",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#nx.closeness_centrality(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "5abeb6eb4835bca0745b419315700eeef9b9ffe5",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#nx.betweenness_centrality(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "6408167ad394dd4bc97445ecdc2b6e7bf52a8adf",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#nx.degree_centrality(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "df9df066f51db3c4e2371ce01af50e8cde23ddcf",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#cross_tab = pd.crosstab(df['age'],df['type'],margins=True)\n",
    "#cross_tab = pd.crosstab(df['type'],df['age'],margins=True)\n",
    "#cross_tab.iloc[:-1,:-1].plot(kind='barh',stacked=True, color=['red','blue', 'yellow'], grid=False,fontsize=10,figsize=(15,6))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#print(cross_tab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cross_tab2 = pd.crosstab(df['author'],df['type'],margins=True)\n",
    "#print(cross_tab2)\n",
    "\n",
    "#fig, axes = plt.subplots(nrows=1, ncols=2, squeeze='False')\n",
    "\n",
    "#df1.plot(ax=axes[0,0])\n",
    "#cross_tab.iloc[:-1,:-1].plot(ax=axes[0], kind='bar',stacked=True, color=['red','blue', 'yellow'], grid=False,fontsize=10,figsize=(5,6))\n",
    "#df2.plot(ax=axes[0,1])\n",
    "#cross_tab2.iloc[:-1,:-1].plot(ax=axes[1], kind='bar',stacked=True, color=['red','turquoise', 'green'], grid=False,fontsize=8,figsize=(12,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "8d625d90be0b57f45637c46e9cd21e24e678a541",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "text_1 = widgets.HTML(value=\"<h1>Types of Genres</h1>\")\n",
    "\n",
    "vbox_text1 = widgets.VBox([text_1])\n",
    "\n",
    "page = widgets.HBox([vbox_text1])\n",
    "display(page)\n",
    "cross_tab = pd.crosstab(df['age'],df['type'],margins=True)\n",
    "\n",
    "cross_tab.iloc[:-1,:-1].plot(kind='barh',stacked=True, color=['red','blue', 'yellow'], grid=False,fontsize=10,figsize=(12,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "bbf7ff80c46c07241356aa9e6d383adb4a1d60dc",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cross_tab2 = pd.crosstab(df['author'],df['type'],margins=True)\n",
    "#print(cross_tab2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "4f7841f23d594f96fcd63de9f6425438b06c48f7",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "text_0 = widgets.HTML(value=\"<h1>Analysis of Poetry</h1>\")\n",
    "\n",
    "vbox_text = widgets.VBox([text_0])\n",
    "\n",
    "page = widgets.HBox([vbox_text])\n",
    "display(page)\n",
    "\n",
    "cross_tab2.iloc[:-1,:-1].plot(kind='bar',stacked=True, color=['red','turquoise', 'green'], grid=False,fontsize=8,figsize=(12,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
